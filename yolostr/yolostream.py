import streamlit as st
from PIL import Image
import numpy as np
import cv2
from ultralytics import YOLO
import json
import streamlit.components.v1 as components
import uuid
import base64
from io import BytesIO

random_filename = f"dommages_detectes_{uuid.uuid4().hex[:8]}.png"

# Configuration - French damage labels
CLASS_NAMES = {
    0: "porte endommagee",
    1: "fenetre endommagee", 
    2: "phare endommage",
    3: "retroviseur endommage",
    4: "bosse",
    5: "capot endommage",
    6: "pare-chocs endommage",
    7: "pare-brise endommage"
}

# Custom CSS for better mobile experience
st.markdown("""
    <style>
        /* Better padding and font scaling for small screens */
        html, body, [class*="css"]  {
            font-size: 16px;
        }

        /* Ensure uploader and image are fully responsive */
        .element-container {
            width: 100% !important;
        }

        img {
            max-width: 100%;
            height: auto;
        }

        /* Mobile-friendly buttons and checkboxes */
        button, .stButton>button, .stCheckbox>label {
            font-size: 1.1em;
        }
    </style>
""", unsafe_allow_html=True)

# Load model
MODEL_PATH = "yolostr/cardmg.pt"
try:
    model = YOLO(MODEL_PATH)
    st.success("Mod√®le charg√© avec succ√®s!")
except Exception as e:
    st.error(f"Erreur de chargement du mod√®le: {str(e)}")
    st.stop()

st.title("üì∑ D√©tection de Dommages sur V√©hicule")

def draw_detections(image, results):
    img_display = image.copy()
    detections = []
    
    for result in results:
        for box in result.boxes:
            conf = float(box.conf)
            if conf >= 0.5:
                x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
                cls_id = int(box.cls)
                class_name = CLASS_NAMES.get(cls_id, f"inconnu {cls_id}")
                
                cv2.rectangle(img_display, (x1, y1), (x2, y2), (0, 255, 0), 2)
                label = f"{class_name} {conf:.2f}"
                cv2.putText(img_display, label, (x1, y1 - 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                
                detections.append({
                    "class_name": class_name,
                    "confidence": conf,
                    "coords": [x1, y1, x2, y2]
                })
    
    return img_display, detections

img_file = st.file_uploader("üìÅ T√©l√©versez une image du v√©hicule", type=["jpg", "jpeg", "png"])

if img_file:
    try:
        image = Image.open(img_file).convert("RGB")
        img_array = np.array(image)
        
        results = model.predict(
            source=img_array,
            conf=0.5,
            imgsz=640,
            device='cpu'
        )
        
        annotated_image, filtered_detections = draw_detections(img_array, results)
        st.image(annotated_image, caption="üõ†Ô∏è Dommages d√©tect√©s ", use_container_width=True)
        
        # Convert annotated image to base64 to send it to Flutter
        annotated_pil = Image.fromarray(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))
        img_bytes = BytesIO()
        annotated_pil.save(img_bytes, format='PNG')
        img_bytes.seek(0)

        # Convert image to base64
        img_base64 = base64.b64encode(img_bytes.read()).decode("utf-8")

        # JavaScript to send the image to Flutter
        components.html(f"""
            <script>
            setTimeout(function() {{
                const base64Image = 'data:image/png;base64,{img_base64}';
                
                if (window.flutter_inappwebview) {{
                    window.flutter_inappwebview.callHandler('sendAnnotatedImage', base64Image)
                        .then(function(response) {{
                            console.log("‚úÖ Annotated image sent to Flutter:", response);
                        }});
                }} else {{
                    console.warn("‚ö†Ô∏è Flutter interface not found.");
                }}
            }}, 1000); // Delay to ensure Flutter is ready
            </script>
        """, height=0)
        
        if filtered_detections:
            st.subheader("‚úÖ Dommages confirm√©s:")
            for det in sorted(filtered_detections, key=lambda x: x["confidence"], reverse=True):
                st.markdown(f"- **{det['class_name']}** (certitude: {det['confidence']:.0%})")

            results_json = json.dumps(filtered_detections)

            components.html(f"""
                <script>
                setTimeout(function() {{
                    const results = {results_json};

                    if (window.flutter_inappwebview) {{
                        window.flutter_inappwebview.callHandler('sendResults', results)
                            .then(function(response) {{
                                console.log("‚úÖ Results sent to Flutter:", response);
                            }});
                    }} else {{
                        console.warn("‚ö†Ô∏è Flutter interface not found.");
                    }}
                }}, 1000); // Delay to ensure Flutter is ready
                </script>
            """, height=0)

        else:
            st.warning("üö´ Aucun dommage significatif d√©tect√©")
            st.info("üîç Conseils pour une meilleure d√©tection :")
            st.markdown("""
                ‚Ä¢ üì∏ Photographiez sous un angle direct  
                ‚Ä¢ üí° Assurez un bon √©clairage  
                ‚Ä¢ üîç Capturez les d√©tails de pr√®s
            """)
        
        if st.checkbox("üõ†Ô∏è Afficher les d√©tails techniques"):
            st.write("Total des d√©tections potentielles:", len(results[0].boxes))
            st.write("D√©tections valid√©es :", len(filtered_detections))
            
    except Exception as e:
        st.error(f"Erreur lors de l'analyse: {str(e)}")
